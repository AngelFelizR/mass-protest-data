---
title: "Characteristics of Successful Protests"
author: "Angel Feliz"
date: "`r format(Sys.Date(),'%d %B %Y')`"
output: 
  html_document:
    css: styles.css
    highlight: tango
    theme: united
    toc: true
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.align = "center", fig.dim = c(12,8))
```

# Motiviation to create the proyect

As data scientist aspirant I was trying to find an interesting dataset which I can use to practice and share what I have learnt so far, when I found out that Datacamp has a [Github repository](https://github.com/datacamp/careerhub-data) with many uncleaned datasets to that I could use.

I saw the folder [Mass Protest Data](https://github.com/datacamp/careerhub-data/tree/master/Mass%20Protest%20Data) very interesting as it describes protests from 1990 to 2020 worldwide. I understand that protests are important to the society and it would be interesting to check what can we learn from this dataset.

# Introduction

The goal of the blog is to define what characteristics share successful protests worldwide and the first step to achieve that it is to define what do I mean with **successful**. As most the protests demand state actions _I consider that a **protest is successful** when there is a reconciliation between the two parts_.

To make that possible we will apply the next skills during the process:

- **Functional programming** with *R*
- **Web scraping** with *rvest*
- **Data manipulation** with *data.table*, *lubridate* and *stringr*
- **Text mining** with *tidytext*
- **Data visualization** with *ggplot2*, *scales* and *forcats*
- **Network visualization** with *igraph* and *ggraph*
- **Automated reporting** with *rmarkdown*, *flextable*, *html* and *css*


# 1. Enveroment set-up

Before starting the find insights from data it's needed to load in R the functions and the data that we will use during the process

## 1.1. Libraries importantion

This first step of the process is to install and load all the libraries to avoid writing the function with the structure `PackageName::FunctionName()` if are going to use many functions of a library.

```{r libraries-importation}
# If you want to reproduce this analysis you can use the same version
# of the packages I used by running the flowing code once:
#
#  if(!require(renv)) install.packages("renv")
#  renv::status()
#  renv::restore()

library(rvest)

library(data.table)
library(lubridate)
library(stringr)

library(flextable)

library(ggplot2)
library(scales)
library(forcats)
theme_set(theme_light())

library(igraph)
library(ggraph)

```


## 1.2. Custom functions

Open-source package are very powerful as they provide general purpose functions, but it's also useful to have some custom functions to perform repetitive task and improve code readability. During this project we will use the following functions:

- **scrap_country_cities:** This function goes to a link direction and check if there is table with the word `City` as one the headers. If the table is found the function returns a `data.table` with the html table and the original link, otherwise returns a empty `data.table` with source link.

```{r define-scrap-function}

scrap_country_cities <- function(link,
                                 secs_to_wait = 2){
  
  #1. Check if the table with countries' cities is in the web page
  #   this step is important to avoid errors during the function application
  PageWithCityTable <-
    read_html(link)|>
    html_element(xpath = '//table//th[text() = "City"]')
  
  HasCityTable <-
    length(PageWithCityTable) > 0
  
  #2. Extract the table to report
  CityTable <-
  if(HaveCityTable){
    
    PageWithCityTable |>
      html_element(xpath = "..") |>
      html_element(xpath = "..") |>
      html_table() |>
      as.data.table() |>
      (\(DT) DT[,link := link])()
    
  }else{
    
    data.table(City = NA_character_,
               Region = NA_character_,
               Population = NA_character_,
               link = link)
  
  }
  
  #3. Waiting some seconds to avoid taking the page down
  Sys.sleep(secs_to_wait)
  
  #4. Export the results
  return(CityTable)
  
}

```

- **style_table:** Takes a `data.frame` and render it as html table with a custom style.

```{r define-style-function}

style_table <- function(df){
  
  df |>
  flextable() |>
  border_remove() |>
  bg(bg = "#008000", part = "header") |>
  bold(part = "header") |>
  color(color = "white", part = "header") |>
  border_inner_h(border = officer::fp_border(color = "#dddddd")) |>
  bg(i = 1:nrow(df) %% 2 != 0, bg = "#f3f3f3") |>
  autofit()
  
}

```


## 1.3. Data importation

In this section we will take the data available and load it into R as `data.table` objects.

### 1.3.1. Main data

**ProtestRaw** will be the main reference to use during the analysis. Any other imported data during this project will be used to extend or clean the information given in this data.

```{r data-importation}

ProtestRaw <-
  fread("Raw-data/protest_data.csv", na.strings = "", integer64 = "double")

pillar::glimpse(ProtestRaw)

```

### 1.3.2. Complementary data

Let's import complementary data to make sense, clean and expand the information provided in `ProtestRaw`.

- **CountryCapital:** It has the capitals of 240 countries.

```{r scrap-country-capital, eval=FALSE, include=TRUE}

WorldCitiesIndexPage <- 
  read_html("https://www.worlddata.info/capital-cities.php")

CountryCapital <-
  WorldCitiesIndexPage |>
  html_table() |>
  rbindlist(use.names = TRUE) |>
  (\(DT) DT[, link :=  
              WorldCitiesIndexPage |> 
              html_element(xpath = str_c('//tr/td/a[text() = "',Country,'"]')) |> 
              html_attr("href") |>
             (\(x) str_c("https://www.worlddata.info",x) )(),
            by = Country
         ][, Population := Population |> str_remove_all(",") |> as.double()])()

pillar::glimpse(CountryCapital)

```

- **CountryCities:** It lists more cities related to the data frame `CountryCapital`.

```{r scrap-country-cities, eval=FALSE, include=TRUE}

CountryCities <-
  CountryCapital$link
  lapply(scrap_country_cities) |>
  rbindlist(use.names = TRUE, fill = TRUE)

pillar::glimpse(CountryCities)

```

- **CountryCode:** It has all possible country codes that the `ProtestRaw` could have to define which country.

```{r country-codes}

CountryCode <-
  countrycode::codelist_panel |>
  as.data.table() |>
  (\(DT) DT[, .SD, 
            .SDcols= c("country.name.en",
                       "country.name.en.regex",
                       names(DT)[sapply(DT, is.double)])] )()

pillar::glimpse(CountryCode)

```

- **Polity4:** It has many political indicators for every country code and year.

```{r eval=FALSE, include=TRUE}

temp <- tempfile(fileext = ".xls")

download.file("http://www.systemicpeace.org/inscr/p4v2018.xls", 
              destfile = temp, mode = 'wb')

Polity4 <- 
  readxl::read_xls(temp) |>
  as.data.table()

pillar::glimpse(Polity4)

```

```{r include=FALSE}

# fwrite(CountryCapital,"Raw-data/Country-Capital.csv")
# fwrite(CountryCities,"Raw-data/Country-Cities.csv")
# fwrite(Polity4,"Raw-data/Polity4.csv")

CountryCapital <-
  fread("Raw-data/Country-Capital.csv", na.strings = "")

CountryCities <-
  fread("Raw-data/Country-Cities.csv", na.strings = "")

Polity4 <-
  fread("Raw-data/Polity4.csv", na.strings = "")

```

# 2. Data understanding

Once we have all the data in R we can start to check the information that contains each column of `ProtestRaw`, as there is no documentation related to the main data we need to check if the columns really have what we think after reading each title.

## 2.1. Checking columns' meaning

Before staring the cleaning process itself we need to understand some general characteristics of data. This step it's crucial in order to know *how to interpret the data* and *what cleaning step are needed*.

Let's see in summary what type of variables holds `ProtestRaw`.

```{r varaible-type-summary}

ProtestRaw |>
  sapply(typeof) |>
  str_to_sentence() |>
  table() |>
  (\(x) c(x,"Total" = sum(x)))() |>
  as.list() |>
  as.data.table() |>
  style_table()

```

- **id** shares an unique number for each row. And we see the test bellow.

```{r id-test}

ProtestRaw[, .(`Number of Rows` = .N,
               `Number of Ids` = uniqueN(id))] |>
  style_table()

```

- **country** stores the names of countries where each protest happened. This dataset has information about 166 countries.

```{r country-unique-count}

ProtestRaw[,.(`Number of Countries` = uniqueN(country))] |>
  style_table()

```

- **ccode** provides a code reference for each country. Most of the countries has one `ccode`, but some change over time as we can see bellow.

```{r ccode-year-change}

ProtestRaw[order(year), 
           .SD[uniqueN(ccode) > 1] |> unique(by = "ccode"),
           by = "country",
           .SDcols = c("ccode","year")] |>
  style_table()

```

Let's the `countrycode` package to find out the `ccode` source. The first step is to select all country codes related to a country name or country regular expression save it as a data.table object.

```{r country-code-selection}

CountryCode[country.name.en == "Ethiopia" &
                year %between% c(1992,1995),
              c("country.name.en","country.name.en.regex",
                "year","p4n", "fao" ,"imf", "un")] |>
  style_table()

```

Now it's time to check which of the possible country code sources from the `countrycode` package match with country codes stored in the `ProtestRaw` data. To make data that we need to perform a join operation, but no all countries have the same names in both tables so we will need to join first the countries that have the same name in both table and math the rest based on regular expressions and bind both joins in a single table and applying a simple anti join we can check that the merge has all countries and years of our original dataset.

```{r county-name-join}

CountryCodeExactMatch <-
  CountryCode[ProtestRaw[, unique(.SD), 
                           .SDcols = c("country","ccode","year")],
                on = c("country.name.en" = "country", "year"),
                nomatch = 0]

CountryCodeRegexMatch <-
ProtestRaw[! country %chin% CountryCodeExactMatch$country.name.en, 
           .(country = unique(country))
    ][, CJ(country = country,
           country.name.en.regex = CountryCode$country.name.en.regex,
           unique = TRUE)
    ][, match_text := str_detect(str_to_lower(country),country.name.en.regex),
      by = .I
    ][order(-match_text),
      unique(.SD, by = "country")
    ][, merge(.SD, CountryCode,  by = "country.name.en.regex", all.x = TRUE),
      .SDcols = c("country.name.en.regex","country")
    ][ProtestRaw[, unique(.SD), .SDcols = c("country","ccode","year")],
      on = c("country", "year"), nomatch = 0
    ][, `:=`(country.name.en = country,
             country = NULL)]

CountryCodeMerged <-
  rbind(CountryCodeExactMatch,
        CountryCodeRegexMatch)

  # Checking it was any country and year that wasn't found
  ProtestRaw[, c("country","year")
  ][!CountryCodeMerged, 
    on = c("country" = "country.name.en","year")] |>
    (\(x) data.table(`Missing Rows` = nrow(x)))() |>
    style_table()

```

Now we can compare which country code is using the `ProtestRaw` to indentify each country.

```{r}

CountryCodeMerged[, !c("year")
  ][, unique(.SD)
  ][, sapply(.SD, \(x) mean(x == ccode, na.rm = TRUE))] |>
  sort(decreasing = TRUE) |>
  (\(x) x[names(x)!="ccode" & seq_along(x) < 8])() |>
  percent(accuracy = 0.01) |>
  (\(x) data.table(`Country Code Source` = names(x),
                   `% Found` = x))()  |>
  style_table()

```

As we can see in the table above the country code source with more matching codes is the [Polity IV Project](http://home.bi.no/a0110709/polityiv_manual.pdf) which monitor regime change and study the effects of regime authority worldwide. This open the door to add more features to our in other stages of project, but first it is important to understand why some the `p4n` didn't match with the original `ccode`.

The *first group* is the one that has a `p4n` the value but it is different to the `ccode` during some years, as you can see bellow. We will correct the `ccode` in those cases during this project.

```{r checking-wrong-code}

CountryCodeMerged[p4n != ccode,
                  .(start_year = min(year),
                    end_year = max(year)),
                  by = c("country.name.en","ccode","p4n")] |>
  style_table()

```

The *second group* correspond to the years when the bellow countries didn't have a `p4n` assign, so we will remand the code that was given by `ccode`.

```{r checking-missing-code}

CountryCodeMerged[is.na(p4n),
                  .(p4n = unique(p4n),
                    start_year = min(year),
                    end_year = max(year)),
                  by = c("country.name.en","ccode")] |>
  style_table()

```

- **region** classifies countries in 8 regions: North America, Central America, South America, Europe, Africa, MENA, Asia and Oceania.

- **location** identifies in which cites the protest took place. It is unstructured we will able to fixed later.

```{r location-check}

  ProtestRaw[country == "United Kingdom", .N,
             .(country, location)
  ][order(-N)
  ][location %like% ",|Edinburgh"
  ][1:5] |>
    style_table()

```

- **protest** shows 1 when the row is related to a protest and 0 otherwise.

- **year**, **startyear**, **startmonth**  and **startday** define when each protest took place.

```{r start-year-check}

  ProtestRaw[, .(`% of year equals to startyear` = 
                   mean(year == startyear, na.rm = TRUE)|> percent())] |>
    style_table() |>
    align(j = 1, align = "center")

```

- **endyear**, **endmonth**  and **endday** defines when each protest ended.

- **protestnumber** counts the number of protests that have occurred during a year in a particular country, but the next table shows the exception to the rule.
 
  - Cambodia in 2003 is missing the first protestnumber
  - Cambodia in 2004 is missing the second protestnumber
  - Yugoslavia in 1992 is duplicating the first protestnumber

As we can not ask any one why that happen we will assume that this was a collection problem and we can correct them during the cleaning process.

```{r protestnumber-exceptions}

  ProtestRaw[order(country,year,startmonth,startday), 
             .SD[max(protestnumber) != uniqueN(id) & unique(protest) != 0],
             by = c("country","year"),
             .SDcols = c("startmonth","startday","id","protestnumber")
  ][1:7
  ][, c("id","year") := lapply(.SD,as.character), 
    .SDcols = c("id","year")] |>
    style_table()

```

- **protesterviolence** shows 1 when there was violence in the protester side and 0 otherwise.

- **participants** has `r ProtestRaw$participants |> uniqueN()` unique values and estimate the number of participants that were part of each protest. As you can see this column needs a lot of cleaning to be useful.

```{r participants-check}

  ProtestRaw[, .N, participants
  ][c(1:3,(length(N)-3):length(N))] |>
    style_table()

```

- **participants_category** has 6 categories to define the number of participants that participated in the protest. Then we will try to complete the missing values using the *participants* column.

```{r participants_category-check}

ProtestRaw[, .N, participants_category]|>
  style_table()

```

- **protesteridentity** has information about the people who protest but some times has information about the protest itself as we can see in the next table.

```{r protesteridentity-check}

  ProtestRaw[, .N, protesteridentity
  ][order(-N)
  ][c(2:4,(length(N)-3):length(N))] |>
  style_table()

```

- The 4 **protesterdemand** columns have 7 categories to define protesters' requests.

```{r protesterdemand-check}

  ProtestRaw[, .SD, .SDcols = patterns("^id$|^protesterdemand")
  ][, melt(.SD, id.vars = "id" , value.name = "Protester Demand")
  ][`Protester Demand` %like% "\\w",
    .(`Number of Protests` = uniqueN(id)), 
    by = "Protester Demand"
  ][order(-`Number of Protests`)] |>
    style_table()

```

- The 7 **stateresponse** columns have 7 categories to define States' responses. By checking the table bellow we can see that *accommodation* was misspelled as *accommodation* which also the attribute that we want to understand.

```{r stateresponse-check}

  ProtestRaw[, .SD, .SDcols = patterns("^id$|^stateresponse")
  ][, melt(.SD, id.vars = "id", value.name = "State Response")
  ][`State Response` %like% "\\w",
    .(`Number of Protests` = uniqueN(id)), 
    by = "State Response"
  ][order(-`Number of Protests`)] |>
    style_table()

```

- **notes** has a paragraph that describes each protest. The average number of words for each paragraph is 98 words which is higher than median so there are some outliers with very long paragraphs.

```{r notes-check}

ProtestRaw[notes %like% "\\w", 
           .(id, `Number of words` = str_squish(notes) |> str_count(" ")+1)
          ][, word_avg := mean(`Number of words`)] |>
  ggplot(aes(`Number of words`))+
  geom_histogram()+
  geom_vline(aes(xintercept = word_avg))+
  scale_x_log10()+
  labs(title = "Distribution of number of words per note")

```

- **sources** has a paragraph that describes where the is information is coming from. The average number of words for each paragraph is 34 words which is higher than median so there are some outliers with very long paragraphs.

```{r sources-check}

ProtestRaw[sources %like% "\\w", 
           .(id, `Number of words` = str_squish(sources) |> str_count(" ")+1)
          ][, word_avg := mean(`Number of words`)] |>
  ggplot(aes(`Number of words`))+
  geom_histogram()+
  geom_vline(aes(xintercept = word_avg))+
  scale_x_log10()+
  labs(title = "Distribution of number of words per source")

```


## 2.2. Understanding the missing values distribution

It is important to know that the data has ***`r nrow(ProtestRaw) |> comma()` rows***, but not all rows represent a protest, ***`r  ProtestRaw[protest == 0] |> nrow() |> comma()` rows*** of the data represent years where the wasn't any protest in a particular country. Let's see how is the missing value distribution in each case.

```{r , fig.dim = c(14,10)}

ProtestRaw[, lapply(.SD, function(x) x |> is.na() |> mean()),
    by = .(protest = fifelse(protest>0,"Protest","No Protest"))
  ][, melt(.SD, id.vars = "protest", 
           variable.name = "Variables",
           value.name = "# Missing")
  ][, Variables := fct_reorder(Variables, `# Missing`, sum)] |>
  ggplot(aes(`# Missing`, `Variables`))+
  geom_blank(aes(x = `# Missing` *1.1))+
  geom_col(fill = "seagreen")+
  geom_text(aes(label = percent(`# Missing`, accuracy = 0.01)),
            hjust = -0.3)+
  scale_x_continuous(labels = percent_format(accuracy = 1))+
  facet_wrap(~protest)+
  labs(title = "Proportions of missing values per variable",
       x = "% Of Missing Values")+
  theme(axis.text = element_text(size = 15),
        axis.title = element_text(size = 16, face = "bold"),
        strip.text = element_text(size = 16, face = "bold"),
        plot.title = element_text(size = 25, face = "bold", 
                                  hjust = 0.5, margin = margin(b = 15)))

```

As we can check the rows that doesn't represent a protest are very empty. We will remove them as they won't be useful to answer the question.

# 3. Data cleaning process

After checking the data feature by feature we got a better sense of the data and a better vision of the problem that need to be solved before getting insight from the data. 

## 3.1. Simple cleaning

In this section we will apply simplest cleaning steps all together.

```{r}

ProtestSimpleClean <-
  
  # Fixing wrong ccodes
  CountryCodeMerged[, .(country = country.name.en, year, p4n)
  ][, unique(.SD)
  ][ProtestRaw, on = c("country","year")
  ][ccode != p4n, ccode := p4n
  ][, !c("p4n")
    
  # Taking out rows that aren't related to a protest
  ][protest == 1, !c("protest")
        
  # Transforming start and end dates to a date format
  ][, `:=`(start_date =  
             paste(startyear,startmonth,startday,sep = "-") |> ymd(),
           end_date =  
             paste(endyear,endmonth,endday,sep = "-") |> ymd())
  ][order(start_date), 
    .SD, .SDcols = !patterns("\\w+year$|\\w+month$|\\w+day$")
   
  # Correcting the protestnumber of each year and country
  ][, protestnumber := 1:.N,
    by = c("country","year")]

```


## 3.2. Completing participants_category with participants column


```{r data-wrangling}

ProtestCategoryClean <-
  
  # Let's work only with protests that are missing participants_category
  ProtestSimpleClean[is.na(participants_category)
                     
                     # Applying general cleaning to participants
  ][,participants := participants |>  
                      str_to_lower() |> 
                      str_remove_all(",") |>
                      str_squish()
    
  # Getting the average of participants intervals
  ][, c("min","max") := tstrsplit(participants,"-| to ", fixed = FALSE)
  ][participants %like% "between \\d+ and \\d+", 
    `:=`(min = str_match(participants, "between (\\d+) and \\d+")[,2],
         max = str_match(participants, "between \\d+ and (\\d+)")[,2])
  ][, c("min","max") := lapply(.(min, max), 
                               \(x) str_extract(x, "\\d+") |> as.double())
  ][, `:=`(participants_clean = (min+max)/2,
           min = NULL,
           max = NULL)
    
  # Getting number of protesters by using regular expressions
  ][participants %like% "^\\d+$" & is.na(participants_clean),
    participants_clean := 
      as.double(participants)
  ][participants %like% "^\\d+\\+$" & is.na(participants_clean),
    participants_clean := 
      str_remove_all(participants,"\\+") |> 
      as.double()
  ][participants %like% "^\\d+s" & is.na(participants_clean),
    participants_clean :=
      str_match(participants,"^(\\d+)s")[,2] |>  
      as.double()
  ][participants %like% "^[><]\\d+" & is.na(participants_clean),
    participants_clean := 
      str_match(participants,"^[><](\\d+)")[,2] |>
      as.double()
    
  # Getting number of protesters by reading the notes variable
  ][id == 922006004, 
    participants_clean := 50
  ][id == 6602002005, 
    participants_clean := 2000
    
  # Creating a new participants_category variable
  ][, `:=`(participants_category = 
             fcase( between(participants_clean, 1, 99), "1-99",
                    between(participants_clean, 100, 999), "100-999",
                    between(participants_clean, 1000, 1999), "1000-1999",
                    between(participants_clean, 2000, 4999), "2000-4999",
                    between(participants_clean, 5000, 10000), "5000-10000",
                    participants_clean > 10000, ">10000",
                    default = "Missing"),
           participants_clean = NULL)
    
  # Adding protests that aren't missing participants_category  
  ][, rbind(.SD,
            ProtestSimpleClean[!is.na(participants_category)])
    
  # Making participants_category a factor variable 
  # to make easier to plot the data later
  ][participants_category == "50-99",
    participants_category := "1-99"
  ][, `:=`(participants_category = factor(participants_category,
                                          levels = c("Missing",   "1-99",     
                                                     "100-999",   "1000-1999", 
                                                     "2000-4999", "5000-10000",
                                                     ">10000")),
           participants = NULL)]


  ProtestCategoryClean[, .N, participants_category] |>
    style_table()

```


## 3.3. Reshaping protesterdemand and stateresponse

```{r}

ProtestReshaped <-
  
  # Melting protesterdemand and stateresponse just keeping protest id
  ProtestCategoryClean[, melt(.SD, id.vars = "id",
                              measure.vars = str_subset(names(.SD),
                                                        "^protesterdemand|^stateresponse"),
                              value.name = "actions",
                              variable.factor = FALSE)
  ][actions %like% "\\w"
  ][,`:=`(variable = fifelse(variable %like% "^protesterdemand", 
                             "demand","response"),
          actions = fifelse(actions == "accomodation","accommodation",actions),
          action_occur = 1L)
  ][, unique(.SD) 
  ][, dcast(.SD, id ~ variable + actions, value.var = "action_occur", fill = 0L)
    
    
  # Adding the other variables to have back the data complete
  ][, merge(.SD, ProtestCategoryClean, by = "id", all = TRUE)
  ][, .SD, .SDcols = !patterns("^protesterdemand|^stateresponse")
  ][,{ 
    ColsToFill <- str_subset(names(.SD),"^(demand|response)")
    copy(.SD)[is.na(response_shootings), (ColsToFill) := 0L] 
  }]

```


## 3.4. Cleaning location data

### 3.4.1. Getting cities names

Getting the global information

Getting specitit information of each country
Let's take that list and create a nice table

```{r}

ColumnsToTakeOut <- 
  setdiff(names(CountryCities),
          c("City","Region","Population","link"))

for (var_name in ColumnsToTakeOut) {
  
  CountryCities[is.na(Region) & !is.na(City) & !is.na(get(var_name)), 
                Region := get(var_name)]
  
}

CountryCities[is.na(Region) & !is.na(City)] |>
  naniar::vis_miss()

CountryCities[, (ColumnsToTakeOut) := NULL]

```




## 3.5. Checking results

After applying the changes we can see that currently all the columns have less
than 5% of missing values.

```{r}

  ProtestReshaped[, lapply(.SD, function(x) mean(is.na(x)))
  ][, id := 1
  ][, melt(.SD, id.vars = "id", 
           variable.name = "Variables",
           value.name = "# Missing")
  ][, `:=`(Variables = fct_reorder(Variables, `# Missing`, sum))] |>
  ggplot(aes(`# Missing`, `Variables`))+
  geom_blank(aes(x = `# Missing` *1.15))+
  geom_col(fill = "forestgreen")+
  geom_text(aes(label = percent(`# Missing`, accuracy = 0.01)), hjust = -0.3)+
  scale_x_continuous(labels = percent_format(accuracy = 0.01))+
  expand_limits(x = 1)+
  labs(title = "Proportions of missing\nvalues per variable",
       x = "% Of Missing Values")+
  theme(axis.text = element_text(size = 15),
        axis.title = element_text(size = 16, face = "bold"),
        strip.text = element_text(size = 16),
        plot.title = element_text(size = 25, face = "bold",
                                  hjust = 0.5, margin = margin(b = 40)))

```


Arel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman, (2018). countrycode: An R package to convert country names and country codes. Journal of Open Source Software, 3(28), 848, https://doi.org/10.21105/joss.00848

https://www.systemicpeace.org/inscrdata.html
